{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7-CORRECT VERSION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLkAuYU7ixAt"
      },
      "source": [
        "**Task 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEnn2KwzRyd"
      },
      "source": [
        "Please note that some numbers might differ slightly from report, although patterns are identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxQRjhkzizr5",
        "outputId": "f3511a85-9a3d-4a83-c14c-44900310749a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#Task 1b\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(125, activation = 'relu'))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8504 - val_loss: 0.2179 - val_accuracy: 0.9341\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1931 - accuracy: 0.9420 - val_loss: 0.1643 - val_accuracy: 0.9498\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1400 - accuracy: 0.9583 - val_loss: 0.1287 - val_accuracy: 0.9602\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9671 - val_loss: 0.1145 - val_accuracy: 0.9643\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9726 - val_loss: 0.1000 - val_accuracy: 0.9688\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.0823 - val_accuracy: 0.9731\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.0903 - val_accuracy: 0.9698\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 0.0771 - val_accuracy: 0.9740\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0767 - val_accuracy: 0.9759\n",
            "Test loss: 0.07673893123865128, Test accuracy 0.9758999943733215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JcXtekyi4ev",
        "outputId": "721a2820-f644-4c21-aef2-1bbfe81758b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#Task 1a\n",
        "print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 125)               98125     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               12600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 116,285\n",
            "Trainable params: 116,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LESAh0ni6nA"
      },
      "source": [
        "#function for ANN-model with 1 hidden layer \n",
        "def one_layer_model(epochs, neurons, learning_rate):\n",
        "\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # the data, split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    ## Define model ##\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(neurons, activation = 'relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                   optimizer=keras.optimizers.SGD(lr = learning_rate),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "    fit_info = model.fit(x_train, y_train,\n",
        "               batch_size=batch_size,\n",
        "               epochs=epochs,\n",
        "               #verbose=1, #verbose=1 in 2a, otherwise 0 \n",
        "               verbose=0,\n",
        "               validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    \n",
        "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "    return score[0], score[1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGiFlnhii8RX"
      },
      "source": [
        "**Task 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilxqqufJi9cp",
        "outputId": "785abacf-fa10-44eb-a490-64aabd673e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Task 2a\n",
        "one_layer_model(30, 100, 0.1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8760 - val_loss: 0.2769 - val_accuracy: 0.9224\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.9267 - val_loss: 0.2245 - val_accuracy: 0.9371\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9402 - val_loss: 0.1907 - val_accuracy: 0.9460\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9491 - val_loss: 0.1666 - val_accuracy: 0.9501\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9561 - val_loss: 0.1488 - val_accuracy: 0.9582\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9605 - val_loss: 0.1353 - val_accuracy: 0.9622\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9647 - val_loss: 0.1263 - val_accuracy: 0.9642\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1169 - accuracy: 0.9677 - val_loss: 0.1170 - val_accuracy: 0.9676\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9704 - val_loss: 0.1131 - val_accuracy: 0.9674\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9726 - val_loss: 0.1109 - val_accuracy: 0.9678\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9743 - val_loss: 0.1013 - val_accuracy: 0.9698\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9757 - val_loss: 0.0970 - val_accuracy: 0.9708\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9709\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0767 - accuracy: 0.9789 - val_loss: 0.0914 - val_accuracy: 0.9730\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0885 - val_accuracy: 0.9732\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9812 - val_loss: 0.0853 - val_accuracy: 0.9738\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9823 - val_loss: 0.0833 - val_accuracy: 0.9744\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9834 - val_loss: 0.0806 - val_accuracy: 0.9747\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9842 - val_loss: 0.0805 - val_accuracy: 0.9750\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9847 - val_loss: 0.0776 - val_accuracy: 0.9753\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9860 - val_loss: 0.0786 - val_accuracy: 0.9752\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9864 - val_loss: 0.0754 - val_accuracy: 0.9771\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0759 - val_accuracy: 0.9771\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.9878 - val_loss: 0.0731 - val_accuracy: 0.9769\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 0.0745 - val_accuracy: 0.9767\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9888 - val_loss: 0.0742 - val_accuracy: 0.9768\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0411 - accuracy: 0.9895 - val_loss: 0.0718 - val_accuracy: 0.9780\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9898 - val_loss: 0.0709 - val_accuracy: 0.9782\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.0731 - val_accuracy: 0.9773\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0713 - val_accuracy: 0.9788\n",
            "Test loss: 0.07130549848079681, Test accuracy 0.9787999987602234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.07130549848079681, 0.9787999987602234)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA41sU2ni_ZE"
      },
      "source": [
        "#Task 2b\n",
        "from statistics import mean \n",
        "\n",
        "def modified_model(epochs, neurons, learning_rate):\n",
        "    accuracy = []\n",
        "    loss = []\n",
        "    \n",
        "    for i in range(3):\n",
        "        res = one_layer_model(epochs, neurons, learning_rate)\n",
        "        accuracy.append(res[1])\n",
        "        loss.append(res[0])\n",
        "        \n",
        "        if i < 2: \n",
        "            print(\"\\nNEXT ITERATION:\")\n",
        "        else:\n",
        "            print(\"THIS WAS THE LAST ITERATION! \\nTHE AVERAGE ACCURACY: \", mean(accuracy), \"\\nAVERAGE LOSS: \", mean(loss))\n",
        "    \n",
        "    return mean(loss), mean(accuracy)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGF_ypq_jBOP",
        "outputId": "6b2b4384-36a0-4dd8-ec68-6904d0818d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "#Task 2b cont.\n",
        "import numpy as np\n",
        "\n",
        "#list of different learning rates\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "\n",
        "#lists for storing validation accuracy & loss\n",
        "accuracy = []\n",
        "loss = []\n",
        "\n",
        "#static parameters\n",
        "epochs = 10\n",
        "neurons = 100\n",
        "\n",
        "#running the model of each learning rates\n",
        "for lr in learning_rates: \n",
        "    print(f\"\\nUSING LEARNING RATE = {lr} \")\n",
        "    res = modified_model(epochs, neurons, lr)\n",
        "    accuracy.append(res[1])\n",
        "    loss.append(res[0])\n",
        "\n",
        "#concetenating model combinations, loss, accuracy for overview of results\n",
        "temp_lr = np.array([learning_rates]).reshape(-1,1)\n",
        "accuracy = np.array([accuracy]).reshape(-1,1)\n",
        "loss = np.array([loss]).reshape(-1,1)\n",
        "\n",
        "#summary of results\n",
        "res = np.concatenate((temp_lr, loss, accuracy),axis=1)\n",
        "print(\"\\nSUMMARY: \\n\", res)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "USING LEARNING RATE = 0.001 \n",
            "Test loss: 0.6711335778236389, Test accuracy 0.8501999974250793\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.6484614610671997, Test accuracy 0.8479999899864197\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.6527645587921143, Test accuracy 0.8564000129699707\n",
            "THIS WAS THE LAST ITERATION! \n",
            "THE AVERAGE ACCURACY:  0.8515333334604899 \n",
            "AVERAGE LOSS:  0.657453199227651\n",
            "\n",
            "USING LEARNING RATE = 0.01 \n",
            "Test loss: 0.2779776155948639, Test accuracy 0.921500027179718\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.27847349643707275, Test accuracy 0.9229000210762024\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.2773444950580597, Test accuracy 0.9229999780654907\n",
            "THIS WAS THE LAST ITERATION! \n",
            "THE AVERAGE ACCURACY:  0.9224666754404703 \n",
            "AVERAGE LOSS:  0.2779318690299988\n",
            "\n",
            "USING LEARNING RATE = 0.1 \n",
            "Test loss: 0.10096163302659988, Test accuracy 0.9700000286102295\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.10493621975183487, Test accuracy 0.9672999978065491\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.10840118676424026, Test accuracy 0.9686999917030334\n",
            "THIS WAS THE LAST ITERATION! \n",
            "THE AVERAGE ACCURACY:  0.968666672706604 \n",
            "AVERAGE LOSS:  0.104766346514225\n",
            "\n",
            "USING LEARNING RATE = 1 \n",
            "Test loss: 0.10759465396404266, Test accuracy 0.968999981880188\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.1017950102686882, Test accuracy 0.9702000021934509\n",
            "\n",
            "NEXT ITERATION:\n",
            "Test loss: 0.08232522010803223, Test accuracy 0.9771999716758728\n",
            "THIS WAS THE LAST ITERATION! \n",
            "THE AVERAGE ACCURACY:  0.9721333185831705 \n",
            "AVERAGE LOSS:  0.09723829478025436\n",
            "\n",
            "SUMMARY: \n",
            " [[0.001      0.6574532  0.85153333]\n",
            " [0.01       0.27793187 0.92246668]\n",
            " [0.1        0.10476635 0.96866667]\n",
            " [1.         0.09723829 0.97213332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQsnJ88tjI8G",
        "outputId": "3da2f55d-faff-4bf2-90f6-548d6c3f242e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Task 2c\n",
        "\n",
        "#list of different learning rates & nr of neurons\n",
        "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "nr_of_neurons = [10, 50, 100, 500, 1000]\n",
        "\n",
        "\n",
        "#lists for storing validation accuracy & loss\n",
        "accuracy = []\n",
        "loss = []\n",
        "\n",
        "#static parameter\n",
        "epochs = 10\n",
        "\n",
        "#temporary lists for storing iteration specific model info\n",
        "temp_lr = []\n",
        "temp_neurons = []\n",
        "\n",
        "#running the model of each pair of learning rates & nr of neurons \n",
        "for lr in learning_rates:\n",
        "    for neurons in nr_of_neurons:\n",
        "        print(f\"\\nUSING {neurons} NR OF NEURONS & LEARNING RATE: {lr}\")\n",
        "        res = one_layer_model(epochs, neurons, lr)\n",
        "        accuracy.append(res[1])\n",
        "        loss.append(res[0])\n",
        "        temp_lr.append(lr)\n",
        "        temp_neurons.append(neurons)\n",
        "        \n",
        "\n",
        "#concetenating model combinations, loss, accuracy for overview of results\n",
        "temp_lr = np.array([temp_lr]).reshape(-1,1)\n",
        "temp_neurons = np.array([temp_neurons]).reshape(-1,1)\n",
        "accuracy = np.array([accuracy]).reshape(-1,1)\n",
        "loss = np.array([loss]).reshape(-1,1)\n",
        "\n",
        "#summary of results\n",
        "res = np.concatenate((temp_lr, temp_neurons, loss, accuracy),axis=1)\n",
        "np.set_printoptions(suppress=True)\n",
        "print(\"\\nSUMMARY: \\n\", res)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "USING 10 NR OF NEURONS & LEARNING RATE: 0.001\n",
            "Test loss: 0.9886183738708496, Test accuracy 0.7634000182151794\n",
            "\n",
            "USING 50 NR OF NEURONS & LEARNING RATE: 0.001\n",
            "Test loss: 0.7027945518493652, Test accuracy 0.8418999910354614\n",
            "\n",
            "USING 100 NR OF NEURONS & LEARNING RATE: 0.001\n",
            "Test loss: 0.6460922360420227, Test accuracy 0.8569999933242798\n",
            "\n",
            "USING 500 NR OF NEURONS & LEARNING RATE: 0.001\n",
            "Test loss: 0.597350537776947, Test accuracy 0.8695999979972839\n",
            "\n",
            "USING 1000 NR OF NEURONS & LEARNING RATE: 0.001\n",
            "Test loss: 0.5789933800697327, Test accuracy 0.8762999773025513\n",
            "\n",
            "USING 10 NR OF NEURONS & LEARNING RATE: 0.005\n",
            "Test loss: 0.4229392111301422, Test accuracy 0.8852999806404114\n",
            "\n",
            "USING 50 NR OF NEURONS & LEARNING RATE: 0.005\n",
            "Test loss: 0.34741124510765076, Test accuracy 0.9072999954223633\n",
            "\n",
            "USING 100 NR OF NEURONS & LEARNING RATE: 0.005\n",
            "Test loss: 0.33225587010383606, Test accuracy 0.90829998254776\n",
            "\n",
            "USING 500 NR OF NEURONS & LEARNING RATE: 0.005\n",
            "Test loss: 0.31641608476638794, Test accuracy 0.9143000245094299\n",
            "\n",
            "USING 1000 NR OF NEURONS & LEARNING RATE: 0.005\n",
            "Test loss: 0.3116869330406189, Test accuracy 0.9162999987602234\n",
            "\n",
            "USING 10 NR OF NEURONS & LEARNING RATE: 0.01\n",
            "Test loss: 0.3395063877105713, Test accuracy 0.9032999873161316\n",
            "\n",
            "USING 50 NR OF NEURONS & LEARNING RATE: 0.01\n",
            "Test loss: 0.2868397831916809, Test accuracy 0.920799970626831\n",
            "\n",
            "USING 100 NR OF NEURONS & LEARNING RATE: 0.01\n",
            "Test loss: 0.27318012714385986, Test accuracy 0.9235000014305115\n",
            "\n",
            "USING 500 NR OF NEURONS & LEARNING RATE: 0.01\n",
            "Test loss: 0.259274423122406, Test accuracy 0.9297000169754028\n",
            "\n",
            "USING 1000 NR OF NEURONS & LEARNING RATE: 0.01\n",
            "Test loss: 0.254607617855072, Test accuracy 0.9293000102043152\n",
            "\n",
            "USING 10 NR OF NEURONS & LEARNING RATE: 0.05\n",
            "Test loss: 0.2554161250591278, Test accuracy 0.9254999756813049\n",
            "\n",
            "USING 50 NR OF NEURONS & LEARNING RATE: 0.05\n",
            "Test loss: 0.16794218122959137, Test accuracy 0.9508000016212463\n",
            "\n",
            "USING 100 NR OF NEURONS & LEARNING RATE: 0.05\n",
            "Test loss: 0.15383845567703247, Test accuracy 0.9555000066757202\n",
            "\n",
            "USING 500 NR OF NEURONS & LEARNING RATE: 0.05\n",
            "Test loss: 0.1331283301115036, Test accuracy 0.9617000222206116\n",
            "\n",
            "USING 1000 NR OF NEURONS & LEARNING RATE: 0.05\n",
            "Test loss: 0.12714648246765137, Test accuracy 0.9638000130653381\n",
            "\n",
            "USING 10 NR OF NEURONS & LEARNING RATE: 0.1\n",
            "Test loss: 0.23410847783088684, Test accuracy 0.9337000250816345\n",
            "\n",
            "USING 50 NR OF NEURONS & LEARNING RATE: 0.1\n",
            "Test loss: 0.12203182280063629, Test accuracy 0.9641000032424927\n",
            "\n",
            "USING 100 NR OF NEURONS & LEARNING RATE: 0.1\n",
            "Test loss: 0.10475633293390274, Test accuracy 0.9696999788284302\n",
            "\n",
            "USING 500 NR OF NEURONS & LEARNING RATE: 0.1\n",
            "Test loss: 0.09373853355646133, Test accuracy 0.9718999862670898\n",
            "\n",
            "USING 1000 NR OF NEURONS & LEARNING RATE: 0.1\n",
            "Test loss: 0.0898544043302536, Test accuracy 0.9743000268936157\n",
            "\n",
            "SUMMARY: \n",
            " [[   0.001        10.            0.98861837    0.76340002]\n",
            " [   0.001        50.            0.70279455    0.84189999]\n",
            " [   0.001       100.            0.64609224    0.85699999]\n",
            " [   0.001       500.            0.59735054    0.8696    ]\n",
            " [   0.001      1000.            0.57899338    0.87629998]\n",
            " [   0.005        10.            0.42293921    0.88529998]\n",
            " [   0.005        50.            0.34741125    0.9073    ]\n",
            " [   0.005       100.            0.33225587    0.90829998]\n",
            " [   0.005       500.            0.31641608    0.91430002]\n",
            " [   0.005      1000.            0.31168693    0.9163    ]\n",
            " [   0.01         10.            0.33950639    0.90329999]\n",
            " [   0.01         50.            0.28683978    0.92079997]\n",
            " [   0.01        100.            0.27318013    0.9235    ]\n",
            " [   0.01        500.            0.25927442    0.92970002]\n",
            " [   0.01       1000.            0.25460762    0.92930001]\n",
            " [   0.05         10.            0.25541613    0.92549998]\n",
            " [   0.05         50.            0.16794218    0.9508    ]\n",
            " [   0.05        100.            0.15383846    0.95550001]\n",
            " [   0.05        500.            0.13312833    0.96170002]\n",
            " [   0.05       1000.            0.12714648    0.96380001]\n",
            " [   0.1          10.            0.23410848    0.93370003]\n",
            " [   0.1          50.            0.12203182    0.9641    ]\n",
            " [   0.1         100.            0.10475633    0.96969998]\n",
            " [   0.1         500.            0.09373853    0.97189999]\n",
            " [   0.1        1000.            0.0898544     0.97430003]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJoCdwv_jK48",
        "outputId": "28f2a0ce-6db4-485a-de89-af1bbeb56a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Task 2c \n",
        "\n",
        "#optimal model (learning rate = 0.1, 1000 neurons) for 30 epochs\n",
        "one_layer_model(30, 1000, 0.1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.05876442790031433, Test accuracy 0.9822999835014343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.05876442790031433, 0.9822999835014343)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-BkjJV3jLUK"
      },
      "source": [
        "**Task 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3R_zyrVjMdb"
      },
      "source": [
        "#Task 3a\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "\n",
        "\n",
        "def noise_model(std_noise):\n",
        "\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    epochs = 30\n",
        "\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # the data, split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    ## Define model ##\n",
        "    model = Sequential()\n",
        "\n",
        "    #adding Gaussian noise layer \n",
        "    model.add(GaussianNoise(std_noise))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation = 'relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                   optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "    fit_info = model.fit(x_train, y_train,\n",
        "               batch_size=batch_size,\n",
        "               epochs=epochs,\n",
        "               verbose=0,\n",
        "               validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    \n",
        "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "    return score[0], score[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Hp5VCqjP8y",
        "outputId": "6c1f2b1b-4846-4b95-c77e-4b3438db451a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Task 3a\n",
        "\n",
        "#list of different standard deviations\n",
        "std_lst = [0.1, 1, 10]\n",
        "accuracy = []\n",
        "loss = []\n",
        "\n",
        "#running the model of each standard deviations\n",
        "for std in std_lst: \n",
        "    print(f\"\\nUSING {std} AS STANDARD DEVIATION FOR GAUSSIAN NOISE LAYER\")\n",
        "    res = noise_model(std)\n",
        "    accuracy.append(res[1])\n",
        "    loss.append(res[0])\n",
        "\n",
        "#concetenating std, loss, accuracy for overview of results\n",
        "temp_std = np.array([std_lst]).reshape(-1,1)\n",
        "accuracy = np.array([accuracy]).reshape(-1,1)\n",
        "loss = np.array([loss]).reshape(-1,1)\n",
        "\n",
        "#summary of results\n",
        "res = np.concatenate((temp_std, loss, accuracy),axis=1)\n",
        "print(\"\\nSUMMARY: \\n\", res)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "USING 0.1 AS STANDARD DEVIATION FOR GAUSSIAN NOISE LAYER\n",
            "Test loss: 0.07335193455219269, Test accuracy 0.9769999980926514\n",
            "\n",
            "USING 1 AS STANDARD DEVIATION FOR GAUSSIAN NOISE LAYER\n",
            "Test loss: 0.16576668620109558, Test accuracy 0.9569000005722046\n",
            "\n",
            "USING 10 AS STANDARD DEVIATION FOR GAUSSIAN NOISE LAYER\n",
            "Test loss: 2.3100173473358154, Test accuracy 0.09740000218153\n",
            "\n",
            "SUMMARY: \n",
            " [[ 0.1         0.07335193  0.977     ]\n",
            " [ 1.          0.16576669  0.9569    ]\n",
            " [10.          2.31001735  0.0974    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd9CTQanjVey"
      },
      "source": [
        "#Task 3b\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def l2_model(reg_factor):\n",
        "\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    epochs = 30\n",
        "\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # the data, split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    ## Define model ##\n",
        "    model = Sequential()\n",
        "\n",
        "    #adding Gaussian noise layer \n",
        "    model.add(GaussianNoise(0.1))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation = 'relu', kernel_regularizer=regularizers.l2(reg_factor)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                   optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "    fit_info = model.fit(x_train, y_train,\n",
        "               batch_size=batch_size,\n",
        "               epochs=epochs,\n",
        "               verbose=0,\n",
        "               validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    \n",
        "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "    return score[0], score[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohSzossKjcZD",
        "outputId": "ae034861-3a1b-438e-e00b-6a13cfcc4f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Task 3b\n",
        "\n",
        "#list of different regularization factors\n",
        "reg_factors = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "accuracy = []\n",
        "loss = []\n",
        "\n",
        "#running the model of each standard deviations\n",
        "for factor in reg_factors:\n",
        "    print(f\"\\nUSING {factor} AS REGULARIZATION FACTOR\")\n",
        "    res = l2_model(factor)\n",
        "    accuracy.append(res[1])\n",
        "    loss.append(res[0])\n",
        "\n",
        "#concetenating std, loss, accuracy for overview of results\n",
        "temp_reg = np.array([reg_factors]).reshape(-1,1)\n",
        "accuracy = np.array([accuracy]).reshape(-1,1)\n",
        "loss = np.array([loss]).reshape(-1,1)\n",
        "\n",
        "#summary of results\n",
        "res = np.concatenate((temp_reg, loss, accuracy),axis=1)\n",
        "print(\"\\nSUMMARY: \\n\", res)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "USING 0.001 AS REGULARIZATION FACTOR\n",
            "Test loss: 0.12717081606388092, Test accuracy 0.9767000079154968\n",
            "\n",
            "USING 0.005 AS REGULARIZATION FACTOR\n",
            "Test loss: 0.18968899548053741, Test accuracy 0.9674999713897705\n",
            "\n",
            "USING 0.01 AS REGULARIZATION FACTOR\n",
            "Test loss: 0.23719187080860138, Test accuracy 0.9591000080108643\n",
            "\n",
            "USING 0.05 AS REGULARIZATION FACTOR\n",
            "Test loss: 0.613048255443573, Test accuracy 0.8978999853134155\n",
            "\n",
            "USING 0.1 AS REGULARIZATION FACTOR\n",
            "Test loss: 0.6976521611213684, Test accuracy 0.8741999864578247\n",
            "\n",
            "SUMMARY: \n",
            " [[0.001      0.12717082 0.97670001]\n",
            " [0.005      0.189689   0.96749997]\n",
            " [0.01       0.23719187 0.95910001]\n",
            " [0.05       0.61304826 0.89789999]\n",
            " [0.1        0.69765216 0.87419999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoBqEeiijfKh"
      },
      "source": [
        "**Task 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCQmbFfOjgLh",
        "outputId": "953a8bc6-ae7b-4d6d-eed3-7a51092eb702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Task 4a\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(GaussianNoise(0.1)) #Gaussian noise layer \n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))  #convolutional layer\n",
        "model.add(MaxPooling2D()) #maxpool\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu')) #convolutional layer\n",
        "model.add(MaxPooling2D()) #maxpool\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation = 'relu', kernel_regularizer=regularizers.l2(0.001))) #l2 regularizer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5397 - accuracy: 0.8857 - val_loss: 0.2880 - val_accuracy: 0.9566\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2464 - accuracy: 0.9696 - val_loss: 0.2146 - val_accuracy: 0.9755\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9777 - val_loss: 0.1741 - val_accuracy: 0.9822\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1695 - accuracy: 0.9811 - val_loss: 0.1632 - val_accuracy: 0.9794\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1444 - accuracy: 0.9844 - val_loss: 0.1328 - val_accuracy: 0.9857\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9861 - val_loss: 0.1140 - val_accuracy: 0.9882\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9861 - val_loss: 0.1155 - val_accuracy: 0.9839\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0980 - accuracy: 0.9889 - val_loss: 0.0978 - val_accuracy: 0.9873\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0899 - accuracy: 0.9886 - val_loss: 0.0866 - val_accuracy: 0.9881\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0791 - accuracy: 0.9901 - val_loss: 0.0795 - val_accuracy: 0.9883\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0730 - accuracy: 0.9900 - val_loss: 0.0864 - val_accuracy: 0.9841\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0658 - accuracy: 0.9913 - val_loss: 0.0843 - val_accuracy: 0.9842\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0620 - accuracy: 0.9913 - val_loss: 0.0675 - val_accuracy: 0.9889\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0583 - accuracy: 0.9916 - val_loss: 0.0650 - val_accuracy: 0.9891\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0533 - accuracy: 0.9927 - val_loss: 0.0620 - val_accuracy: 0.9895\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0507 - accuracy: 0.9930 - val_loss: 0.0633 - val_accuracy: 0.9879\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0486 - accuracy: 0.9925 - val_loss: 0.0639 - val_accuracy: 0.9872\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0453 - accuracy: 0.9937 - val_loss: 0.0709 - val_accuracy: 0.9857\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0434 - accuracy: 0.9936 - val_loss: 0.1228 - val_accuracy: 0.9695\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0476 - accuracy: 0.9924 - val_loss: 0.0589 - val_accuracy: 0.9877\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0397 - accuracy: 0.9942 - val_loss: 0.0583 - val_accuracy: 0.9876\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0390 - accuracy: 0.9941 - val_loss: 0.0534 - val_accuracy: 0.9886\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0386 - accuracy: 0.9941 - val_loss: 0.0762 - val_accuracy: 0.9815\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0366 - accuracy: 0.9944 - val_loss: 0.0492 - val_accuracy: 0.9891\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0354 - accuracy: 0.9948 - val_loss: 0.0610 - val_accuracy: 0.9869\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0351 - accuracy: 0.9950 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0343 - accuracy: 0.9948 - val_loss: 0.0479 - val_accuracy: 0.9906\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0366 - accuracy: 0.9941 - val_loss: 0.0479 - val_accuracy: 0.9907\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0347 - accuracy: 0.9949 - val_loss: 0.0508 - val_accuracy: 0.9900\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0331 - accuracy: 0.9951 - val_loss: 0.0476 - val_accuracy: 0.9904\n",
            "Test loss: 0.047613076865673065, Test accuracy 0.9904000163078308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZI-2s6vpfJZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}